{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823cd505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Accelerometer_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Accelerometer.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Accelerometer_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cc9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Activity_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Activity.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Activity_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae84355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted files to Gyroscope_CUA\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the name of the uploaded zip file\n",
    "uploaded_zip_file = 'Gyroscope.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the contents\n",
    "extracted_dir = 'Gyroscope_CUA'\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(extracted_dir):\n",
    "    os.makedirs(extracted_dir)\n",
    "\n",
    "# Open the uploaded zip file\n",
    "zip_file_path = os.path.join(os.getcwd(), uploaded_zip_file)\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all the contents into the target directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "print(f\"Successfully extracted files to {extracted_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecee609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Accelerometer_CUA/Accelerometer'\n",
    "\n",
    "# Define column labels for Accelerometer data\n",
    "accelerometer_labels = ['Systime', 'Event Time', 'ActivityID', 'X', 'Y', 'Z', 'Phone_orientation']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the accelerometer description\n",
    "            current_df.columns = accelerometer_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c581ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Gyroscope_CUA/Gyroscope'\n",
    "\n",
    "# Define column labels for Gyroscope data\n",
    "gyroscope_labels = ['Systime', 'EventTime', 'ActivityID', 'X', 'Y', 'Z', 'Phone_orientation']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the gyroscope description\n",
    "            current_df.columns = gyroscope_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e12e109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column labels updated for all CSV files in the folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = 'Activity_CUA/Activity'\n",
    "\n",
    "# Define column labels for Gyroscope data\n",
    "gyroscope_labels = ['ID', 'SubjectID', 'Session_number', 'Start_time', 'End_time', 'Relative_Start_time', 'Relative_End_time','Gesture_scenario','TaskID','ContentID']\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file is empty before attempting to read\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            # Read the current CSV file\n",
    "            current_df = pd.read_csv(file_path)\n",
    "\n",
    "            # Label the columns according to the gyroscope description\n",
    "            current_df.columns = gyroscope_labels\n",
    "\n",
    "            # Save the DataFrame back to the same CSV file\n",
    "            current_df.to_csv(file_path, index=False)\n",
    "        else:\n",
    "            print(f\"Warning: Empty file - {file_name}\")\n",
    "\n",
    "print(\"Column labels updated for all CSV files in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039ba126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Phone_orientation</th>\n",
       "      <th>X</th>\n",
       "      <th>Systime</th>\n",
       "      <th>EventTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100669011000001</td>\n",
       "      <td>0.128893</td>\n",
       "      <td>-1.016174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267864</td>\n",
       "      <td>1396226205573</td>\n",
       "      <td>6785142573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100669011000001</td>\n",
       "      <td>-0.536034</td>\n",
       "      <td>-0.844521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.215330</td>\n",
       "      <td>1396226205575</td>\n",
       "      <td>6785152583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100669011000001</td>\n",
       "      <td>-0.471893</td>\n",
       "      <td>1.282512</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.426079</td>\n",
       "      <td>1396226205577</td>\n",
       "      <td>6785162593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100669011000001</td>\n",
       "      <td>0.765720</td>\n",
       "      <td>-0.275500</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.072082</td>\n",
       "      <td>1396226205600</td>\n",
       "      <td>6785172602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100669011000001</td>\n",
       "      <td>-0.105680</td>\n",
       "      <td>-0.409280</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034208</td>\n",
       "      <td>1396226205604</td>\n",
       "      <td>6785182673000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ActivityID         Y         Z  Phone_orientation         X  \\\n",
       "0  100669011000001  0.128893 -1.016174                  0  0.267864   \n",
       "1  100669011000001 -0.536034 -0.844521                  0  0.215330   \n",
       "2  100669011000001 -0.471893  1.282512                  0 -0.426079   \n",
       "3  100669011000001  0.765720 -0.275500                  0 -0.072082   \n",
       "4  100669011000001 -0.105680 -0.409280                  0 -0.034208   \n",
       "\n",
       "         Systime      EventTime  \n",
       "0  1396226205573  6785142573000  \n",
       "1  1396226205575  6785152583000  \n",
       "2  1396226205577  6785162593000  \n",
       "3  1396226205600  6785172602000  \n",
       "4  1396226205604  6785182673000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Gyroscope_CUA/Gyroscope'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate =  len(csv_files)\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "Gyroscope_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if Gyroscope_df.empty:\n",
    "        Gyroscope_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = set(Gyroscope_df.columns) & set(df.columns)\n",
    "        Gyroscope_df = pd.concat([Gyroscope_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "Gyroscope_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9eec653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Time</th>\n",
       "      <th>ActivityID</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Phone_orientation</th>\n",
       "      <th>X</th>\n",
       "      <th>Systime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6785142543000</td>\n",
       "      <td>100669011000001</td>\n",
       "      <td>7.472902</td>\n",
       "      <td>6.092046</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101754</td>\n",
       "      <td>1396226205572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6785152552000</td>\n",
       "      <td>100669011000001</td>\n",
       "      <td>7.411850</td>\n",
       "      <td>6.323685</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.121506</td>\n",
       "      <td>1396226205574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6785162562000</td>\n",
       "      <td>100669011000001</td>\n",
       "      <td>7.313688</td>\n",
       "      <td>6.293758</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.126893</td>\n",
       "      <td>1396226205576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6785172572000</td>\n",
       "      <td>100669011000001</td>\n",
       "      <td>7.307702</td>\n",
       "      <td>6.186019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.083797</td>\n",
       "      <td>1396226205598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6785182643000</td>\n",
       "      <td>100669011000001</td>\n",
       "      <td>7.389704</td>\n",
       "      <td>6.066308</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003591</td>\n",
       "      <td>1396226205601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Event Time       ActivityID         Y         Z  Phone_orientation  \\\n",
       "0  6785142543000  100669011000001  7.472902  6.092046                  0   \n",
       "1  6785152552000  100669011000001  7.411850  6.323685                  0   \n",
       "2  6785162562000  100669011000001  7.313688  6.293758                  0   \n",
       "3  6785172572000  100669011000001  7.307702  6.186019                  0   \n",
       "4  6785182643000  100669011000001  7.389704  6.066308                  0   \n",
       "\n",
       "          X        Systime  \n",
       "0 -0.101754  1396226205572  \n",
       "1 -0.121506  1396226205574  \n",
       "2 -0.126893  1396226205576  \n",
       "3 -0.083797  1396226205598  \n",
       "4 -0.003591  1396226205601  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Accelerometer_CUA/Accelerometer'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate = len(csv_files)\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "A_concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if A_concatenated_df.empty:\n",
    "        A_concatenated_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = set(A_concatenated_df.columns) & set(df.columns)\n",
    "        A_concatenated_df = pd.concat([A_concatenated_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "A_concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b98cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContentID</th>\n",
       "      <th>End_time</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Start_time</th>\n",
       "      <th>Relative_End_time</th>\n",
       "      <th>Session_number</th>\n",
       "      <th>TaskID</th>\n",
       "      <th>Gesture_scenario</th>\n",
       "      <th>Relative_Start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1396226578198</td>\n",
       "      <td>100669</td>\n",
       "      <td>100669012000001</td>\n",
       "      <td>1396226421894</td>\n",
       "      <td>7157788</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1396226650781</td>\n",
       "      <td>100669</td>\n",
       "      <td>100669012000002</td>\n",
       "      <td>1396226600720</td>\n",
       "      <td>7230371</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7180310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1396226653876</td>\n",
       "      <td>100669</td>\n",
       "      <td>100669012000002</td>\n",
       "      <td>1396226600720</td>\n",
       "      <td>7233466</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7180310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1396226737648</td>\n",
       "      <td>100669</td>\n",
       "      <td>100669012000003</td>\n",
       "      <td>1396226672419</td>\n",
       "      <td>7317238</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7252008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1396226937462</td>\n",
       "      <td>100669</td>\n",
       "      <td>100669013000001</td>\n",
       "      <td>1396226745978</td>\n",
       "      <td>7517052</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7325568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ContentID       End_time  SubjectID               ID     Start_time  \\\n",
       "0          2  1396226578198     100669  100669012000001  1396226421894   \n",
       "1          2  1396226650781     100669  100669012000002  1396226600720   \n",
       "2          2  1396226653876     100669  100669012000002  1396226600720   \n",
       "3          2  1396226737648     100669  100669012000003  1396226672419   \n",
       "4          3  1396226937462     100669  100669013000001  1396226745978   \n",
       "\n",
       "   Relative_End_time  Session_number  TaskID  Gesture_scenario  \\\n",
       "0            7157788               1       7                 1   \n",
       "1            7230371               1       7                 1   \n",
       "2            7233466               1       7                 1   \n",
       "3            7317238               1       7                 1   \n",
       "4            7517052               1       7                 1   \n",
       "\n",
       "   Relative_Start_time  \n",
       "0              7001484  \n",
       "1              7180310  \n",
       "2              7180310  \n",
       "3              7252008  \n",
       "4              7325568  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Activity_CUA/Activity'\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the number of files to concatenate is not greater than the total available files\n",
    "files_to_concatenate =  len(csv_files)\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "Act_concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the specified number of files and concatenate rows\n",
    "for i in range(files_to_concatenate):\n",
    "    file_path = os.path.join(folder_path, csv_files[i])\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure consistent columns\n",
    "    if Act_concatenated_df.empty:\n",
    "        Act_concatenated_df = df\n",
    "    else:\n",
    "        # Keep only columns that are present in both DataFrames\n",
    "        common_columns = set(Act_concatenated_df.columns) & set(df.columns)\n",
    "        Act_concatenated_df = pd.concat([Act_concatenated_df[common_columns], df[common_columns]], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "Act_concatenated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5e2804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ContentID       End_time  SubjectID               ID     Start_time  \\\n",
      "0            2  1396226578198     100669  100669012000001  1396226421894   \n",
      "1            2  1396226650781     100669  100669012000002  1396226600720   \n",
      "2            2  1396226653876     100669  100669012000002  1396226600720   \n",
      "3            2  1396226737648     100669  100669012000003  1396226672419   \n",
      "4            3  1396226937462     100669  100669013000001  1396226745978   \n",
      "..         ...            ...        ...              ...            ...   \n",
      "117          3  1399075996157     186676  186676053000002  1399075988761   \n",
      "118          3  1399076004460     186676  186676053000003  1399076000278   \n",
      "119          3  1399076017448     186676  186676053000004  1399076014044   \n",
      "120          2  1399158518576     186676  186676062000001  1399158333135   \n",
      "121          3  1399158883323     186676  186676063000001  1399158518621   \n",
      "\n",
      "     Relative_End_time  Session_number  TaskID  Gesture_scenario  \\\n",
      "0              7157788               1       7                 1   \n",
      "1              7230371               1       7                 1   \n",
      "2              7233466               1       7                 1   \n",
      "3              7317238               1       7                 1   \n",
      "4              7517052               1       7                 1   \n",
      "..                 ...             ...     ...               ...   \n",
      "117            6813498               5       7                 1   \n",
      "118            6821802               5       7                 1   \n",
      "119            6834790               5       7                 1   \n",
      "120             482315               6       3                 1   \n",
      "121             847062               6       3                 1   \n",
      "\n",
      "     Relative_Start_time  \n",
      "0                7001484  \n",
      "1                7180310  \n",
      "2                7180310  \n",
      "3                7252008  \n",
      "4                7325568  \n",
      "..                   ...  \n",
      "117              6806102  \n",
      "118              6817620  \n",
      "119              6831385  \n",
      "120               296874  \n",
      "121               482360  \n",
      "\n",
      "[122 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Act_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2236bb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Event Time       ActivityID         Y         Z  \\\n",
      "0        6785142543000  100669011000001  7.472902  6.092046   \n",
      "1        6785152552000  100669011000001  7.411850  6.323685   \n",
      "2        6785162562000  100669011000001  7.313688  6.293758   \n",
      "3        6785172572000  100669011000001  7.307702  6.186019   \n",
      "4        6785182643000  100669011000001  7.389704  6.066308   \n",
      "...                ...              ...       ...       ...   \n",
      "1763585   847019860000  186676063000001  8.057087  5.989694   \n",
      "1763586   847030542000  186676063000001  8.067862  5.854422   \n",
      "1763587   847041986000  186676063000001  8.082227  5.513248   \n",
      "1763588   847054193000  186676063000001  8.135497  5.259462   \n",
      "1763589   847059014000  186676063000001  8.185776  5.042788   \n",
      "\n",
      "         Phone_orientation         X        Systime  \n",
      "0                        0 -0.101754  1396226205572  \n",
      "1                        0 -0.121506  1396226205574  \n",
      "2                        0 -0.126893  1396226205576  \n",
      "3                        0 -0.083797  1396226205598  \n",
      "4                        0 -0.003591  1396226205601  \n",
      "...                    ...       ...            ...  \n",
      "1763585                  0 -2.065597  1399158883282  \n",
      "1763586                  0 -2.062006  1399158883292  \n",
      "1763587                  0 -2.127248  1399158883304  \n",
      "1763588                  0 -2.097321  1399158883318  \n",
      "1763589                  0 -2.085948  1399158883488  \n",
      "\n",
      "[1763590 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490db24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ActivityID         Y         Z  Phone_orientation         X  \\\n",
      "0        100669011000001  0.128893 -1.016174                  0  0.267864   \n",
      "1        100669011000001 -0.536034 -0.844521                  0  0.215330   \n",
      "2        100669011000001 -0.471893  1.282512                  0 -0.426079   \n",
      "3        100669011000001  0.765720 -0.275500                  0 -0.072082   \n",
      "4        100669011000001 -0.105680 -0.409280                  0 -0.034208   \n",
      "...                  ...       ...       ...                ...       ...   \n",
      "1763333  186676063000001 -0.228158 -0.027184                  0 -0.050091   \n",
      "1763334  186676063000001 -0.153327 -0.021991                  0 -0.017410   \n",
      "1763335  186676063000001 -0.099266 -0.018631                  0  0.046731   \n",
      "1763336  186676063000001 -0.032070 -0.014966                  0  0.107512   \n",
      "1763337  186676063000001  0.031154 -0.007636                  0  0.132863   \n",
      "\n",
      "               Systime      EventTime  \n",
      "0        1396226205573  6785142573000  \n",
      "1        1396226205575  6785152583000  \n",
      "2        1396226205577  6785162593000  \n",
      "3        1396226205600  6785172602000  \n",
      "4        1396226205604  6785182673000  \n",
      "...                ...            ...  \n",
      "1763333  1399158883282   847019891000  \n",
      "1763334  1399158883293   847030572000  \n",
      "1763335  1399158883305   847042016000  \n",
      "1763336  1399158883319   847054193000  \n",
      "1763337  1399158883489   847059014000  \n",
      "\n",
      "[1763338 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gyroscope_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7093a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "Gyroscope_df['ID'] =Gyroscope_df['ActivityID'].astype(str).str[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31560789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Event Time       ActivityID         Y         Z  \\\n",
      "0        6785142543000  100669011000001  7.472902  6.092046   \n",
      "1        6785152552000  100669011000001  7.411850  6.323685   \n",
      "2        6785162562000  100669011000001  7.313688  6.293758   \n",
      "3        6785172572000  100669011000001  7.307702  6.186019   \n",
      "4        6785182643000  100669011000001  7.389704  6.066308   \n",
      "...                ...              ...       ...       ...   \n",
      "1763585   847019860000  186676063000001  8.057087  5.989694   \n",
      "1763586   847030542000  186676063000001  8.067862  5.854422   \n",
      "1763587   847041986000  186676063000001  8.082227  5.513248   \n",
      "1763588   847054193000  186676063000001  8.135497  5.259462   \n",
      "1763589   847059014000  186676063000001  8.185776  5.042788   \n",
      "\n",
      "         Phone_orientation         X        Systime  \n",
      "0                        0 -0.101754  1396226205572  \n",
      "1                        0 -0.121506  1396226205574  \n",
      "2                        0 -0.126893  1396226205576  \n",
      "3                        0 -0.083797  1396226205598  \n",
      "4                        0 -0.003591  1396226205601  \n",
      "...                    ...       ...            ...  \n",
      "1763585                  0 -2.065597  1399158883282  \n",
      "1763586                  0 -2.062006  1399158883292  \n",
      "1763587                  0 -2.127248  1399158883304  \n",
      "1763588                  0 -2.097321  1399158883318  \n",
      "1763589                  0 -2.085948  1399158883488  \n",
      "\n",
      "[1763590 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62c0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "A_concatenated_df['ID'] =A_concatenated_df['ActivityID'].astype(str).str[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cacd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ActivityID         Y         Z  Phone_orientation         X  \\\n",
      "0        100669011000001  0.128893 -1.016174                  0  0.267864   \n",
      "1        100669011000001 -0.536034 -0.844521                  0  0.215330   \n",
      "2        100669011000001 -0.471893  1.282512                  0 -0.426079   \n",
      "3        100669011000001  0.765720 -0.275500                  0 -0.072082   \n",
      "4        100669011000001 -0.105680 -0.409280                  0 -0.034208   \n",
      "...                  ...       ...       ...                ...       ...   \n",
      "1763333  186676063000001 -0.228158 -0.027184                  0 -0.050091   \n",
      "1763334  186676063000001 -0.153327 -0.021991                  0 -0.017410   \n",
      "1763335  186676063000001 -0.099266 -0.018631                  0  0.046731   \n",
      "1763336  186676063000001 -0.032070 -0.014966                  0  0.107512   \n",
      "1763337  186676063000001  0.031154 -0.007636                  0  0.132863   \n",
      "\n",
      "               Systime      EventTime      ID  \n",
      "0        1396226205573  6785142573000  100669  \n",
      "1        1396226205575  6785152583000  100669  \n",
      "2        1396226205577  6785162593000  100669  \n",
      "3        1396226205600  6785172602000  100669  \n",
      "4        1396226205604  6785182673000  100669  \n",
      "...                ...            ...     ...  \n",
      "1763333  1399158883282   847019891000  186676  \n",
      "1763334  1399158883293   847030572000  186676  \n",
      "1763335  1399158883305   847042016000  186676  \n",
      "1763336  1399158883319   847054193000  186676  \n",
      "1763337  1399158883489   847059014000  186676  \n",
      "\n",
      "[1763338 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gyroscope_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Gyroscope_df.drop(['Systime', 'EventTime', 'ActivityID'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9537d427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Y         Z  Phone_orientation         X      ID\n",
      "0        0.128893 -1.016174                  0  0.267864  100669\n",
      "1       -0.536034 -0.844521                  0  0.215330  100669\n",
      "2       -0.471893  1.282512                  0 -0.426079  100669\n",
      "3        0.765720 -0.275500                  0 -0.072082  100669\n",
      "4       -0.105680 -0.409280                  0 -0.034208  100669\n",
      "...           ...       ...                ...       ...     ...\n",
      "1763333 -0.228158 -0.027184                  0 -0.050091  186676\n",
      "1763334 -0.153327 -0.021991                  0 -0.017410  186676\n",
      "1763335 -0.099266 -0.018631                  0  0.046731  186676\n",
      "1763336 -0.032070 -0.014966                  0  0.107512  186676\n",
      "1763337  0.031154 -0.007636                  0  0.132863  186676\n",
      "\n",
      "[1763338 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gyroscope_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d200f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A_concatenated_df.drop(['Systime', 'Event Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1dafc3",
   "metadata": {},
   "source": [
    "# GYROSCOPE X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a25c603",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyroxy)  Centroid Distance(gyroxy)  \\\n",
      "0      100669                0.616612                   0.157566   \n",
      "1      100669                1.580424                   0.178812   \n",
      "2      100669                0.950282                   0.150707   \n",
      "3      100669                0.903312                   0.386830   \n",
      "4      100669                0.570392                   0.240423   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                1.003663                   0.126849   \n",
      "17629  186676                0.796665                   0.152636   \n",
      "17630  186676                0.463958                   0.137867   \n",
      "17631  186676                0.441687                   0.231708   \n",
      "17632  186676                0.597854                   0.112320   \n",
      "\n",
      "       Polygon Area(gyroxy)  Polygon Perimeter(gyroxy)  \n",
      "0                  0.423369                   6.120407  \n",
      "1                  0.004262                   4.980247  \n",
      "2                  0.006709                   4.109890  \n",
      "3                  2.700508                  15.419713  \n",
      "4                  0.166164                   5.134611  \n",
      "...                     ...                        ...  \n",
      "17628              0.123106                   4.975900  \n",
      "17629              0.003211                   7.123988  \n",
      "17630              0.032050                   2.759303  \n",
      "17631              0.074344                   5.116394  \n",
      "17632              0.090549                   2.887727  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    x_ferret = np.max(x_values) - np.min(x_values)\n",
    "    y_ferret = np.max(y_values) - np.min(y_values)\n",
    "    F = x_ferret / y_ferret if y_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    centroid_x = np.mean(x_values)\n",
    "    centroid_y = np.mean(y_values)\n",
    "    distances = np.sqrt((np.array(x_values) - centroid_x) ** 2 + (np.array(y_values) - centroid_y) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    area = 0.5 * np.abs(np.dot(x_values, np.roll(y_values, 1)) - np.dot(y_values, np.roll(x_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    dx = np.diff(x_values)\n",
    "    dy = np.diff(y_values)\n",
    "    perimeter = np.sum(np.sqrt(dx**2 + dy**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(gyroxy)', 'Centroid Distance(gyroxy)', 'Polygon Area(gyroxy)', 'Polygon Perimeter(gyroxy)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "gyroxy_features = process_data_in_windows(Gyroscope_df)\n",
    "\n",
    "print(gyroxy_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc5a8f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# GYROSCOPE Y,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1e8960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyroyz)  Centroid Distance(gyroyz)  \\\n",
      "0      100669                0.566303                   0.179661   \n",
      "1      100669                1.242532                   0.133076   \n",
      "2      100669                1.998975                   0.106603   \n",
      "3      100669                0.420213                   1.632013   \n",
      "4      100669                3.081395                   0.230317   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                2.667752                   0.103266   \n",
      "17629  186676                2.685323                   0.119757   \n",
      "17630  186676                2.854115                   0.138280   \n",
      "17631  186676                0.781973                   0.330728   \n",
      "17632  186676                5.150000                   0.095842   \n",
      "\n",
      "       Polygon Area(gyroyz)  Polygon Perimeter(gyroyz)  \n",
      "0                  1.491053                   8.126881  \n",
      "1                  0.003931                   3.977403  \n",
      "2                  0.035998                   3.321722  \n",
      "3                  2.770916                  18.024492  \n",
      "4                  0.134135                   4.248676  \n",
      "...                     ...                        ...  \n",
      "17628              0.041392                   3.372787  \n",
      "17629              0.042997                   4.658971  \n",
      "17630              0.039409                   2.326254  \n",
      "17631              0.154903                   5.451413  \n",
      "17632              0.010040                   1.922962  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    y_ferret = np.max(y_values) - np.min(y_values)\n",
    "    z_ferret = np.max(z_values) - np.min(z_values)\n",
    "    F = y_ferret / z_ferret if z_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    centroid_y = np.mean(y_values)\n",
    "    centroid_z = np.mean(z_values)\n",
    "    distances = np.sqrt((np.array(y_values) - centroid_y) ** 2 + (np.array(z_values) - centroid_z) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    area = 0.5 * np.abs(np.dot(y_values, np.roll(z_values, 1)) - np.dot(z_values, np.roll(y_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    dy = np.diff(y_values)\n",
    "    dz = np.diff(z_values)\n",
    "    perimeter = np.sum(np.sqrt(dy**2 + dz**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(gyroyz)', 'Centroid Distance(gyroyz)', 'Polygon Area(gyroyz)', 'Polygon Perimeter(gyroyz)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "gyroyz_features = process_data_in_windows(Gyroscope_df)\n",
    "\n",
    "print(gyroyz_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a679b1",
   "metadata": {},
   "source": [
    "# GYROSCOPE Z,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f2ceead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyrozx)  Centroid Distance(gyrozx)  \\\n",
      "0      100669                2.863775                   0.188755   \n",
      "1      100669                0.509236                   0.180096   \n",
      "2      100669                0.526429                   0.135639   \n",
      "3      100669                2.634466                   1.646785   \n",
      "4      100669                0.568957                   0.125642   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                0.373479                   0.084747   \n",
      "17629  186676                0.467442                   0.105985   \n",
      "17630  186676                0.755179                   0.083622   \n",
      "17631  186676                2.895304                   0.236960   \n",
      "17632  186676                0.324786                   0.060704   \n",
      "\n",
      "       Polygon Area(gyrozx)  Polygon Perimeter(gyrozx)  \n",
      "0                  0.021297                   6.197423  \n",
      "1                  0.143342                   3.590862  \n",
      "2                  0.012133                   3.025889  \n",
      "3                  0.124263                  17.490223  \n",
      "4                  0.089153                   3.228899  \n",
      "...                     ...                        ...  \n",
      "17628              0.017589                   3.697555  \n",
      "17629              0.048751                   5.106712  \n",
      "17630              0.008091                   1.878394  \n",
      "17631              0.099311                   4.379561  \n",
      "17632              0.012136                   2.056794  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    z_ferret = np.max(z_values) - np.min(z_values)\n",
    "    x_ferret = np.max(x_values) - np.min(x_values)\n",
    "    F = z_ferret / x_ferret if x_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    centroid_z = np.mean(z_values)\n",
    "    centroid_x = np.mean(x_values)\n",
    "    distances = np.sqrt((np.array(z_values) - centroid_z) ** 2 + (np.array(x_values) - centroid_x) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    area = 0.5 * np.abs(np.dot(z_values, np.roll(x_values, 1)) - np.dot(x_values, np.roll(z_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    dz = np.diff(z_values)\n",
    "    dx = np.diff(x_values)\n",
    "    perimeter = np.sum(np.sqrt(dz**2 + dx**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(gyrozx)', 'Centroid Distance(gyrozx)', 'Polygon Area(gyrozx)', 'Polygon Perimeter(gyrozx)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "gyrozx_features = process_data_in_windows(Gyroscope_df)\n",
    "\n",
    "print(gyrozx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a44e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f8b641",
   "metadata": {},
   "source": [
    "# ACCELEROMETER X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6a44fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ActivityID', 'Y', 'Z', 'Phone_orientation', 'X', 'ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print column names of A_concatenated_df\n",
    "print(A_concatenated_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c351e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_concatenated_df.drop(['ActivityID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f285dfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Y', 'Z', 'Phone_orientation', 'X', 'ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(A_concatenated_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e9b20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.653896                  0.307439   \n",
      "1      100669               1.046059                  0.356021   \n",
      "2      100669               1.561073                  0.288214   \n",
      "3      100669               0.985135                  4.509599   \n",
      "4      100669               1.534549                  0.371832   \n",
      "...       ...                    ...                       ...   \n",
      "17630  186676               1.094025                  0.142493   \n",
      "17631  186676               0.869119                  0.146733   \n",
      "17632  186676               0.942703                  0.115567   \n",
      "17633  186676               4.717417                  0.791349   \n",
      "17634  186676               2.830576                  0.201599   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  \n",
      "0                 0.126997                 10.049717  \n",
      "1                 0.396814                 11.305019  \n",
      "2                 0.019777                 10.251685  \n",
      "3                 4.987873                 35.311697  \n",
      "4                 0.361496                  8.355046  \n",
      "...                    ...                       ...  \n",
      "17630             0.049188                  8.843841  \n",
      "17631             0.024362                  9.870242  \n",
      "17632             0.072951                  6.465457  \n",
      "17633             0.729006                 12.611915  \n",
      "17634             0.093240                  6.948079  \n",
      "\n",
      "[17635 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    x_ferret = np.max(x_values) - np.min(x_values)\n",
    "    y_ferret = np.max(y_values) - np.min(y_values)\n",
    "    F = x_ferret / y_ferret if y_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    centroid_x = np.mean(x_values)\n",
    "    centroid_y = np.mean(y_values)\n",
    "    distances = np.sqrt((np.array(x_values) - centroid_x) ** 2 + (np.array(y_values) - centroid_y) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    area = 0.5 * np.abs(np.dot(x_values, np.roll(y_values, 1)) - np.dot(y_values, np.roll(x_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    x_values, y_values = data['X'], data['Y']\n",
    "    dx = np.diff(x_values)\n",
    "    dy = np.diff(y_values)\n",
    "    perimeter = np.sum(np.sqrt(dx**2 + dy**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(accxy)', 'Centroid Distance(accxy)', 'Polygon Area(accxy)', 'Polygon Perimeter(accxy)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "acceleroxy_features = process_data_in_windows(A_concatenated_df)\n",
    "\n",
    "print(acceleroxy_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda78e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebc3c44b",
   "metadata": {},
   "source": [
    "# ACCELEROMETER Y,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6c0944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accyz)  Centroid Distance(accyz)  \\\n",
      "0      100669               0.740989                  0.399202   \n",
      "1      100669               0.297710                  0.674483   \n",
      "2      100669               0.253358                  0.451814   \n",
      "3      100669               1.414049                  3.522641   \n",
      "4      100669               0.408537                  0.625104   \n",
      "...       ...                    ...                       ...   \n",
      "17630  186676               0.356121                  0.340417   \n",
      "17631  186676               0.335727                  0.319892   \n",
      "17632  186676               0.422626                  0.227916   \n",
      "17633  186676               0.677952                  0.352900   \n",
      "17634  186676               0.151661                  0.241693   \n",
      "\n",
      "       Polygon Area(accyz)  Polygon Perimeter(accyz)  \n",
      "0                 0.471914                 12.862190  \n",
      "1                 0.833709                 20.952302  \n",
      "2                 0.083674                 22.086376  \n",
      "3                 3.416576                 35.021401  \n",
      "4                 0.156925                 16.248545  \n",
      "...                    ...                       ...  \n",
      "17630             0.350555                 17.036324  \n",
      "17631             1.157944                 20.086476  \n",
      "17632             0.227560                 13.446345  \n",
      "17633             0.795358                 14.096204  \n",
      "17634             0.367337                 14.297470  \n",
      "\n",
      "[17635 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    y_ferret = np.max(y_values) - np.min(y_values)\n",
    "    z_ferret = np.max(z_values) - np.min(z_values)\n",
    "    F = y_ferret / z_ferret if z_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    centroid_y = np.mean(y_values)\n",
    "    centroid_z = np.mean(z_values)\n",
    "    distances = np.sqrt((np.array(y_values) - centroid_y) ** 2 + (np.array(z_values) - centroid_z) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    area = 0.5 * np.abs(np.dot(y_values, np.roll(z_values, 1)) - np.dot(z_values, np.roll(y_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    y_values, z_values = data['Y'], data['Z']\n",
    "    dy = np.diff(y_values)\n",
    "    dz = np.diff(z_values)\n",
    "    perimeter = np.sum(np.sqrt(dy**2 + dz**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(accyz)', 'Centroid Distance(accyz)', 'Polygon Area(accyz)', 'Polygon Perimeter(accyz)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "acceleroyz_features = process_data_in_windows(A_concatenated_df)\n",
    "\n",
    "print(acceleroyz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae90317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6ad7e40",
   "metadata": {},
   "source": [
    "# ACCELEROMETER Z,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c69228ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(acczx)  Centroid Distance(acczx)  \\\n",
      "0      100669               2.863775                  0.188755   \n",
      "1      100669               0.509236                  0.180096   \n",
      "2      100669               0.526429                  0.135639   \n",
      "3      100669               2.634466                  1.646785   \n",
      "4      100669               0.568957                  0.125642   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               0.373479                  0.084747   \n",
      "17629  186676               0.467442                  0.105985   \n",
      "17630  186676               0.755179                  0.083622   \n",
      "17631  186676               2.895304                  0.236960   \n",
      "17632  186676               0.324786                  0.060704   \n",
      "\n",
      "       Polygon Area(acczx)  Polygon Perimeter(acczx)  \n",
      "0                 0.021297                  6.197423  \n",
      "1                 0.143342                  3.590862  \n",
      "2                 0.012133                  3.025889  \n",
      "3                 0.124263                 17.490223  \n",
      "4                 0.089153                  3.228899  \n",
      "...                    ...                       ...  \n",
      "17628             0.017589                  3.697555  \n",
      "17629             0.048751                  5.106712  \n",
      "17630             0.008091                  1.878394  \n",
      "17631             0.099311                  4.379561  \n",
      "17632             0.012136                  2.056794  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Feature extraction functions as defined earlier\n",
    "def extract_ferret_measure(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    z_ferret = np.max(z_values) - np.min(z_values)\n",
    "    x_ferret = np.max(x_values) - np.min(x_values)\n",
    "    F = z_ferret / x_ferret if x_ferret != 0 else np.nan\n",
    "    return F\n",
    "\n",
    "def extract_centroid_distance(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    centroid_z = np.mean(z_values)\n",
    "    centroid_x = np.mean(x_values)\n",
    "    distances = np.sqrt((np.array(z_values) - centroid_z) ** 2 + (np.array(x_values) - centroid_x) ** 2)\n",
    "    centroid_distance = np.mean(distances)\n",
    "    return centroid_distance\n",
    "\n",
    "def extract_polygon_area(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    area = 0.5 * np.abs(np.dot(z_values, np.roll(x_values, 1)) - np.dot(x_values, np.roll(z_values, 1)))\n",
    "    return area\n",
    "\n",
    "def extract_polygon_perimeter(data):\n",
    "    z_values, x_values = data['Z'], data['X']\n",
    "    dz = np.diff(z_values)\n",
    "    dx = np.diff(x_values)\n",
    "    perimeter = np.sum(np.sqrt(dz**2 + dx**2))\n",
    "    return perimeter\n",
    "\n",
    "\n",
    "# Function to process data in windows of 100 rows and include 'ID'\n",
    "def process_data_in_windows(df, window_size=100):\n",
    "    windowed_features = []\n",
    "\n",
    "    for start in range(0, len(df), window_size):\n",
    "        end = start + window_size\n",
    "        window_data = df.iloc[start:end]\n",
    "\n",
    "        if len(window_data) < window_size:\n",
    "            continue  # Skip incomplete windows\n",
    "\n",
    "        # Extracting features\n",
    "        ferret_measure = extract_ferret_measure(window_data)\n",
    "        centroid_distance = extract_centroid_distance(window_data)\n",
    "        polygon_area = extract_polygon_area(window_data)\n",
    "        polygon_perimeter = extract_polygon_perimeter(window_data)\n",
    "\n",
    "        # Get the 'ID' from the first row in the window\n",
    "        window_id = window_data.iloc[0]['ID']\n",
    "\n",
    "        windowed_features.append([window_id, ferret_measure, centroid_distance, polygon_area, polygon_perimeter])\n",
    "\n",
    "    return pd.DataFrame(windowed_features, columns=['ID', 'Ferret Measure(acczx)', 'Centroid Distance(acczx)', 'Polygon Area(acczx)', 'Polygon Perimeter(acczx)'])\n",
    "\n",
    "# Replace 'Gyroscope_df' with your actual DataFrame variable\n",
    "accelerozx_features = process_data_in_windows(Gyroscope_df)\n",
    "\n",
    "print(accelerozx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab15d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accyz)  Centroid Distance(accyz)  \\\n",
      "0      100669               0.740989                  0.399202   \n",
      "1      100669               0.297710                  0.674483   \n",
      "2      100669               0.253358                  0.451814   \n",
      "3      100669               1.414049                  3.522641   \n",
      "4      100669               0.408537                  0.625104   \n",
      "...       ...                    ...                       ...   \n",
      "17630  186676               0.356121                  0.340417   \n",
      "17631  186676               0.335727                  0.319892   \n",
      "17632  186676               0.422626                  0.227916   \n",
      "17633  186676               0.677952                  0.352900   \n",
      "17634  186676               0.151661                  0.241693   \n",
      "\n",
      "       Polygon Area(accyz)  Polygon Perimeter(accyz)  \n",
      "0                 0.471914                 12.862190  \n",
      "1                 0.833709                 20.952302  \n",
      "2                 0.083674                 22.086376  \n",
      "3                 3.416576                 35.021401  \n",
      "4                 0.156925                 16.248545  \n",
      "...                    ...                       ...  \n",
      "17630             0.350555                 17.036324  \n",
      "17631             1.157944                 20.086476  \n",
      "17632             0.227560                 13.446345  \n",
      "17633             0.795358                 14.096204  \n",
      "17634             0.367337                 14.297470  \n",
      "\n",
      "[17635 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(acceleroyz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e9f7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleroxy_features = acceleroxy_features[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e25fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.653896                  0.307439   \n",
      "1      100669               1.046059                  0.356021   \n",
      "2      100669               1.561073                  0.288214   \n",
      "3      100669               0.985135                  4.509599   \n",
      "4      100669               1.534549                  0.371832   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               1.183922                  0.158304   \n",
      "17629  186676               0.973371                  0.154844   \n",
      "17630  186676               1.094025                  0.142493   \n",
      "17631  186676               0.869119                  0.146733   \n",
      "17632  186676               0.942703                  0.115567   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  \n",
      "0                 0.126997                 10.049717  \n",
      "1                 0.396814                 11.305019  \n",
      "2                 0.019777                 10.251685  \n",
      "3                 4.987873                 35.311697  \n",
      "4                 0.361496                  8.355046  \n",
      "...                    ...                       ...  \n",
      "17628             0.033820                  9.379900  \n",
      "17629             0.189392                  9.418644  \n",
      "17630             0.049188                  8.843841  \n",
      "17631             0.024362                  9.870242  \n",
      "17632             0.072951                  6.465457  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(acceleroxy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "452fe6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.053376                  0.061894   \n",
      "1      100669               0.101684                  0.072494   \n",
      "2      100669               0.165124                  0.057699   \n",
      "3      100669               0.094179                  0.978768   \n",
      "4      100669               0.161857                  0.075943   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               0.118666                  0.029354   \n",
      "17629  186676               0.092730                  0.028599   \n",
      "17630  186676               0.107592                  0.025904   \n",
      "17631  186676               0.079888                  0.026829   \n",
      "17632  186676               0.088952                  0.020029   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  \n",
      "0                 0.002688                  0.075813  \n",
      "1                 0.008400                  0.087172  \n",
      "2                 0.000419                  0.077641  \n",
      "3                 0.105582                  0.304400  \n",
      "4                 0.007652                  0.060479  \n",
      "...                    ...                       ...  \n",
      "17628             0.000716                  0.069752  \n",
      "17629             0.004009                  0.070103  \n",
      "17630             0.001041                  0.064902  \n",
      "17631             0.000516                  0.074189  \n",
      "17632             0.001544                  0.043381  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_acceleroxy = normalize_dataframe_excluding_id(acceleroxy_features, 'ID')\n",
    "\n",
    "print(normalized_acceleroxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c9249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accyz)  Centroid Distance(accyz)  \\\n",
      "0      100669               0.275119                  0.093037   \n",
      "1      100669               0.093330                  0.161819   \n",
      "2      100669               0.075142                  0.106183   \n",
      "3      100669               0.551141                  0.873459   \n",
      "4      100669               0.138780                  0.149481   \n",
      "...       ...                    ...                       ...   \n",
      "17630  186676               0.117285                  0.078349   \n",
      "17631  186676               0.108921                  0.073221   \n",
      "17632  186676               0.144558                  0.050240   \n",
      "17633  186676               0.249268                  0.081468   \n",
      "17634  186676               0.033435                  0.053682   \n",
      "\n",
      "       Polygon Area(accyz)  Polygon Perimeter(accyz)  \n",
      "0                 0.008967                  0.081195  \n",
      "1                 0.015841                  0.141317  \n",
      "2                 0.001590                  0.149745  \n",
      "3                 0.064918                  0.245871  \n",
      "4                 0.002981                  0.106361  \n",
      "...                    ...                       ...  \n",
      "17630             0.006661                  0.112215  \n",
      "17631             0.022002                  0.134883  \n",
      "17632             0.004324                  0.085537  \n",
      "17633             0.015112                  0.090366  \n",
      "17634             0.006979                  0.091862  \n",
      "\n",
      "[17635 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_acceleroyz = normalize_dataframe_excluding_id(acceleroyz_features, 'ID')\n",
    "\n",
    "print(normalized_acceleroyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62765242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(acczx)  Centroid Distance(acczx)  \\\n",
      "0      100669               0.374142                  0.104882   \n",
      "1      100669               0.058186                  0.099886   \n",
      "2      100669               0.060493                  0.074236   \n",
      "3      100669               0.343371                  0.946111   \n",
      "4      100669               0.066200                  0.068469   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               0.039969                  0.044873   \n",
      "17629  186676               0.052578                  0.057127   \n",
      "17630  186676               0.091189                  0.044224   \n",
      "17631  186676               0.378373                  0.132694   \n",
      "17632  186676               0.033435                  0.031001   \n",
      "\n",
      "       Polygon Area(acczx)  Polygon Perimeter(acczx)  \n",
      "0                 0.003716                  0.138271  \n",
      "1                 0.025011                  0.075452  \n",
      "2                 0.002117                  0.061836  \n",
      "3                 0.021682                  0.410432  \n",
      "4                 0.015556                  0.066728  \n",
      "...                    ...                       ...  \n",
      "17628             0.003069                  0.078023  \n",
      "17629             0.008506                  0.111984  \n",
      "17630             0.001412                  0.034181  \n",
      "17631             0.017329                  0.094460  \n",
      "17632             0.002118                  0.038480  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_accelerozx = normalize_dataframe_excluding_id(accelerozx_features, 'ID')\n",
    "\n",
    "print(normalized_accelerozx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f451bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyroxy)  Centroid Distance(gyroxy)  \\\n",
      "0      100669                0.080112                   0.097613   \n",
      "1      100669                0.240486                   0.111414   \n",
      "2      100669                0.135633                   0.093157   \n",
      "3      100669                0.127818                   0.246544   \n",
      "4      100669                0.072421                   0.151437   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                0.144516                   0.077659   \n",
      "17629  186676                0.110072                   0.094410   \n",
      "17630  186676                0.054711                   0.084816   \n",
      "17631  186676                0.051005                   0.145776   \n",
      "17632  186676                0.076991                   0.068220   \n",
      "\n",
      "       Polygon Area(gyroxy)  Polygon Perimeter(gyroxy)  \n",
      "0                  0.039899                   0.115210  \n",
      "1                  0.000402                   0.091714  \n",
      "2                  0.000632                   0.073778  \n",
      "3                  0.254502                   0.306844  \n",
      "4                  0.015660                   0.094895  \n",
      "...                     ...                        ...  \n",
      "17628              0.011602                   0.091624  \n",
      "17629              0.000303                   0.135891  \n",
      "17630              0.003020                   0.045946  \n",
      "17631              0.007006                   0.094520  \n",
      "17632              0.008533                   0.048593  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_gyroxy = normalize_dataframe_excluding_id(gyroxy_features, 'ID')\n",
    "\n",
    "print(normalized_gyroxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce3c6a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyroyz)  Centroid Distance(gyroyz)  \\\n",
      "0      100669                0.034273                   0.095521   \n",
      "1      100669                0.085346                   0.069850   \n",
      "2      100669                0.142477                   0.055262   \n",
      "3      100669                0.023239                   0.895854   \n",
      "4      100669                0.224228                   0.123435   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                0.192988                   0.053423   \n",
      "17629  186676                0.194315                   0.062510   \n",
      "17630  186676                0.207063                   0.072718   \n",
      "17631  186676                0.050562                   0.178768   \n",
      "17632  186676                0.380462                   0.049332   \n",
      "\n",
      "       Polygon Area(gyroyz)  Polygon Perimeter(gyroyz)  \n",
      "0                  0.124569                   0.222375  \n",
      "1                  0.000328                   0.102574  \n",
      "2                  0.003007                   0.083643  \n",
      "3                  0.231494                   0.508132  \n",
      "4                  0.011206                   0.110406  \n",
      "...                     ...                        ...  \n",
      "17628              0.003458                   0.085117  \n",
      "17629              0.003592                   0.122251  \n",
      "17630              0.003292                   0.054903  \n",
      "17631              0.012941                   0.145130  \n",
      "17632              0.000839                   0.043259  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_gyroyz = normalize_dataframe_excluding_id(gyroyz_features, 'ID')\n",
    "\n",
    "print(normalized_gyroyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03375770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(gyrozx)  Centroid Distance(gyrozx)  \\\n",
      "0      100669                0.374142                   0.104882   \n",
      "1      100669                0.058186                   0.099886   \n",
      "2      100669                0.060493                   0.074236   \n",
      "3      100669                0.343371                   0.946111   \n",
      "4      100669                0.066200                   0.068469   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                0.039969                   0.044873   \n",
      "17629  186676                0.052578                   0.057127   \n",
      "17630  186676                0.091189                   0.044224   \n",
      "17631  186676                0.378373                   0.132694   \n",
      "17632  186676                0.033435                   0.031001   \n",
      "\n",
      "       Polygon Area(gyrozx)  Polygon Perimeter(gyrozx)  \n",
      "0                  0.003716                   0.138271  \n",
      "1                  0.025011                   0.075452  \n",
      "2                  0.002117                   0.061836  \n",
      "3                  0.021682                   0.410432  \n",
      "4                  0.015556                   0.066728  \n",
      "...                     ...                        ...  \n",
      "17628              0.003069                   0.078023  \n",
      "17629              0.008506                   0.111984  \n",
      "17630              0.001412                   0.034181  \n",
      "17631              0.017329                   0.094460  \n",
      "17632              0.002118                   0.038480  \n",
      "\n",
      "[17633 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe_excluding_id(df, id_column):\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the ID column and store it separately\n",
    "    id_col = df_copy[id_column]\n",
    "\n",
    "    # Columns to be normalized (excluding the ID column)\n",
    "    columns_to_normalize = [col for col in df_copy.columns if col != id_column]\n",
    "\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Normalize the data\n",
    "    df_copy[columns_to_normalize] = scaler.fit_transform(df_copy[columns_to_normalize])\n",
    "\n",
    "    # Replace the ID column with its original values\n",
    "    df_copy[id_column] = id_col\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Normalize the DataFrame excluding 'ID'\n",
    "normalized_gyrozx = normalize_dataframe_excluding_id(gyrozx_features, 'ID')\n",
    "\n",
    "print(normalized_gyrozx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96eddd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Ferret Measure(gyroxy)', 'Centroid Distance(gyroxy)',\n",
      "       'Polygon Area(gyroxy)', 'Polygon Perimeter(gyroxy)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(gyroyz)', 'Centroid Distance(gyroyz)',\n",
      "       'Polygon Area(gyroyz)', 'Polygon Perimeter(gyroyz)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(gyrozx)', 'Centroid Distance(gyrozx)',\n",
      "       'Polygon Area(gyrozx)', 'Polygon Perimeter(gyrozx)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(gyroxy_features.columns)\n",
    "print(gyroyz_features.columns)\n",
    "print(gyrozx_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e177ff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Ferret Measure(gyroxy)', 'Centroid Distance(gyroxy)',\n",
      "       'Polygon Area(gyroxy)', 'Polygon Perimeter(gyroxy)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(gyroyz)', 'Centroid Distance(gyroyz)',\n",
      "       'Polygon Area(gyroyz)', 'Polygon Perimeter(gyroyz)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(gyrozx)', 'Centroid Distance(gyrozx)',\n",
      "       'Polygon Area(gyrozx)', 'Polygon Perimeter(gyrozx)'],\n",
      "      dtype='object')\n",
      "           ID  Ferret Measure(gyroxy)  Centroid Distance(gyroxy)  \\\n",
      "0      100669                0.616612                   0.157566   \n",
      "1      100669                1.580424                   0.178812   \n",
      "2      100669                0.950282                   0.150707   \n",
      "3      100669                0.903312                   0.386830   \n",
      "4      100669                0.570392                   0.240423   \n",
      "...       ...                     ...                        ...   \n",
      "17628  186676                1.003663                   0.126849   \n",
      "17629  186676                0.796665                   0.152636   \n",
      "17630  186676                0.463958                   0.137867   \n",
      "17631  186676                0.441687                   0.231708   \n",
      "17632  186676                0.597854                   0.112320   \n",
      "\n",
      "       Polygon Area(gyroxy)  Polygon Perimeter(gyroxy)  \\\n",
      "0                  0.423369                   6.120407   \n",
      "1                  0.004262                   4.980247   \n",
      "2                  0.006709                   4.109890   \n",
      "3                  2.700508                  15.419713   \n",
      "4                  0.166164                   5.134611   \n",
      "...                     ...                        ...   \n",
      "17628              0.123106                   4.975900   \n",
      "17629              0.003211                   7.123988   \n",
      "17630              0.032050                   2.759303   \n",
      "17631              0.074344                   5.116394   \n",
      "17632              0.090549                   2.887727   \n",
      "\n",
      "       Ferret Measure(gyroyz)  Centroid Distance(gyroyz)  \\\n",
      "0                    0.566303                   0.179661   \n",
      "1                    1.242532                   0.133076   \n",
      "2                    1.998975                   0.106603   \n",
      "3                    0.420213                   1.632013   \n",
      "4                    3.081395                   0.230317   \n",
      "...                       ...                        ...   \n",
      "17628                2.667752                   0.103266   \n",
      "17629                2.685323                   0.119757   \n",
      "17630                2.854115                   0.138280   \n",
      "17631                0.781973                   0.330728   \n",
      "17632                5.150000                   0.095842   \n",
      "\n",
      "       Polygon Area(gyroyz)  Polygon Perimeter(gyroyz)  \\\n",
      "0                  1.491053                   8.126881   \n",
      "1                  0.003931                   3.977403   \n",
      "2                  0.035998                   3.321722   \n",
      "3                  2.770916                  18.024492   \n",
      "4                  0.134135                   4.248676   \n",
      "...                     ...                        ...   \n",
      "17628              0.041392                   3.372787   \n",
      "17629              0.042997                   4.658971   \n",
      "17630              0.039409                   2.326254   \n",
      "17631              0.154903                   5.451413   \n",
      "17632              0.010040                   1.922962   \n",
      "\n",
      "       Ferret Measure(gyrozx)  Centroid Distance(gyrozx)  \\\n",
      "0                    2.863775                   0.188755   \n",
      "1                    0.509236                   0.180096   \n",
      "2                    0.526429                   0.135639   \n",
      "3                    2.634466                   1.646785   \n",
      "4                    0.568957                   0.125642   \n",
      "...                       ...                        ...   \n",
      "17628                0.373479                   0.084747   \n",
      "17629                0.467442                   0.105985   \n",
      "17630                0.755179                   0.083622   \n",
      "17631                2.895304                   0.236960   \n",
      "17632                0.324786                   0.060704   \n",
      "\n",
      "       Polygon Area(gyrozx)  Polygon Perimeter(gyrozx)  \n",
      "0                  0.021297                   6.197423  \n",
      "1                  0.143342                   3.590862  \n",
      "2                  0.012133                   3.025889  \n",
      "3                  0.124263                  17.490223  \n",
      "4                  0.089153                   3.228899  \n",
      "...                     ...                        ...  \n",
      "17628              0.017589                   3.697555  \n",
      "17629              0.048751                   5.106712  \n",
      "17630              0.008091                   1.878394  \n",
      "17631              0.099311                   4.379561  \n",
      "17632              0.012136                   2.056794  \n",
      "\n",
      "[17633 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'gyroxy_features', 'gyroyz_features', 'gyrozx_features' with your actual dataframe variables\n",
    "gyroxy_features = gyroxy_features# your dataframe\n",
    "gyroyz_features = gyroyz_features# your dataframe\n",
    "gyrozx_features = gyrozx_features# your dataframe\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(gyroxy_features.columns)\n",
    "print(gyroyz_features.columns)\n",
    "print(gyrozx_features.columns)\n",
    "\n",
    "# Assuming the ID column is named correctly and exists in your dataframes\n",
    "# Extract the 'ID' column from one dataframe and set it aside\n",
    "id_column = gyroxy_features[['ID']]  # Replace 'ID' with the actual column name if it's different\n",
    "\n",
    "# Drop the 'ID' column from the other dataframes to avoid duplication\n",
    "gyroxy_features.drop(columns=['ID'], inplace=True)\n",
    "gyroyz_features.drop(columns=['ID'], inplace=True)\n",
    "gyrozx_features.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Concatenate the dataframes horizontally\n",
    "Gyro_all_df = pd.concat([id_column, gyroxy_features, gyroyz_features, gyrozx_features], axis=1)\n",
    "\n",
    "print(Gyro_all_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ee964e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Ferret Measure(accxy)', 'Centroid Distance(accxy)',\n",
      "       'Polygon Area(accxy)', 'Polygon Perimeter(accxy)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(accyz)', 'Centroid Distance(accyz)',\n",
      "       'Polygon Area(accyz)', 'Polygon Perimeter(accyz)'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'Ferret Measure(acczx)', 'Centroid Distance(acczx)',\n",
      "       'Polygon Area(acczx)', 'Polygon Perimeter(acczx)'],\n",
      "      dtype='object')\n",
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.653896                  0.307439   \n",
      "1      100669               1.046059                  0.356021   \n",
      "2      100669               1.561073                  0.288214   \n",
      "3      100669               0.985135                  4.509599   \n",
      "4      100669               1.534549                  0.371832   \n",
      "...       ...                    ...                       ...   \n",
      "17630  186676               1.094025                  0.142493   \n",
      "17631  186676               0.869119                  0.146733   \n",
      "17632  186676               0.942703                  0.115567   \n",
      "17633     NaN                    NaN                       NaN   \n",
      "17634     NaN                    NaN                       NaN   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  Ferret Measure(accyz)  \\\n",
      "0                 0.126997                 10.049717               0.740989   \n",
      "1                 0.396814                 11.305019               0.297710   \n",
      "2                 0.019777                 10.251685               0.253358   \n",
      "3                 4.987873                 35.311697               1.414049   \n",
      "4                 0.361496                  8.355046               0.408537   \n",
      "...                    ...                       ...                    ...   \n",
      "17630             0.049188                  8.843841               0.356121   \n",
      "17631             0.024362                  9.870242               0.335727   \n",
      "17632             0.072951                  6.465457               0.422626   \n",
      "17633                  NaN                       NaN               0.677952   \n",
      "17634                  NaN                       NaN               0.151661   \n",
      "\n",
      "       Centroid Distance(accyz)  Polygon Area(accyz)  \\\n",
      "0                      0.399202             0.471914   \n",
      "1                      0.674483             0.833709   \n",
      "2                      0.451814             0.083674   \n",
      "3                      3.522641             3.416576   \n",
      "4                      0.625104             0.156925   \n",
      "...                         ...                  ...   \n",
      "17630                  0.340417             0.350555   \n",
      "17631                  0.319892             1.157944   \n",
      "17632                  0.227916             0.227560   \n",
      "17633                  0.352900             0.795358   \n",
      "17634                  0.241693             0.367337   \n",
      "\n",
      "       Polygon Perimeter(accyz)  Ferret Measure(acczx)  \\\n",
      "0                     12.862190               2.863775   \n",
      "1                     20.952302               0.509236   \n",
      "2                     22.086376               0.526429   \n",
      "3                     35.021401               2.634466   \n",
      "4                     16.248545               0.568957   \n",
      "...                         ...                    ...   \n",
      "17630                 17.036324               0.755179   \n",
      "17631                 20.086476               2.895304   \n",
      "17632                 13.446345               0.324786   \n",
      "17633                 14.096204                    NaN   \n",
      "17634                 14.297470                    NaN   \n",
      "\n",
      "       Centroid Distance(acczx)  Polygon Area(acczx)  Polygon Perimeter(acczx)  \n",
      "0                      0.188755             0.021297                  6.197423  \n",
      "1                      0.180096             0.143342                  3.590862  \n",
      "2                      0.135639             0.012133                  3.025889  \n",
      "3                      1.646785             0.124263                 17.490223  \n",
      "4                      0.125642             0.089153                  3.228899  \n",
      "...                         ...                  ...                       ...  \n",
      "17630                  0.083622             0.008091                  1.878394  \n",
      "17631                  0.236960             0.099311                  4.379561  \n",
      "17632                  0.060704             0.012136                  2.056794  \n",
      "17633                       NaN                  NaN                       NaN  \n",
      "17634                       NaN                  NaN                       NaN  \n",
      "\n",
      "[17635 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'gyroxy_features', 'gyroyz_features', 'gyrozx_features' with your actual dataframe variables\n",
    "acceleroxy_features = acceleroxy_features# your dataframe\n",
    "acceleroyz_features = acceleroyz_features# your dataframe\n",
    "accelerozx_features = accelerozx_features# your dataframe\n",
    "\n",
    "# Check the column names and adjust if necessary\n",
    "print(acceleroxy_features.columns)\n",
    "print(acceleroyz_features.columns)\n",
    "print(accelerozx_features.columns)\n",
    "\n",
    "# Assuming the ID column is named correctly and exists in your dataframes\n",
    "# Extract the 'ID' column from one dataframe and set it aside\n",
    "id_column = acceleroxy_features[['ID']]  # Replace 'ID' with the actual column name if it's different\n",
    "\n",
    "# Drop the 'ID' column from the other dataframes to avoid duplication\n",
    "acceleroxy_features.drop(columns=['ID'], inplace=True)\n",
    "acceleroyz_features.drop(columns=['ID'], inplace=True)\n",
    "accelerozx_features.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Concatenate the dataframes horizontally\n",
    "Accelero_all_df = pd.concat([id_column, acceleroxy_features, acceleroyz_features, accelerozx_features], axis=1)\n",
    "\n",
    "print(Accelero_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d745af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accelero_all_df = Accelero_all_df[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbb0aec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.653896                  0.307439   \n",
      "1      100669               1.046059                  0.356021   \n",
      "2      100669               1.561073                  0.288214   \n",
      "3      100669               0.985135                  4.509599   \n",
      "4      100669               1.534549                  0.371832   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               1.183922                  0.158304   \n",
      "17629  186676               0.973371                  0.154844   \n",
      "17630  186676               1.094025                  0.142493   \n",
      "17631  186676               0.869119                  0.146733   \n",
      "17632  186676               0.942703                  0.115567   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  Ferret Measure(accyz)  \\\n",
      "0                 0.126997                 10.049717               0.740989   \n",
      "1                 0.396814                 11.305019               0.297710   \n",
      "2                 0.019777                 10.251685               0.253358   \n",
      "3                 4.987873                 35.311697               1.414049   \n",
      "4                 0.361496                  8.355046               0.408537   \n",
      "...                    ...                       ...                    ...   \n",
      "17628             0.033820                  9.379900               0.197403   \n",
      "17629             0.189392                  9.418644               0.290865   \n",
      "17630             0.049188                  8.843841               0.356121   \n",
      "17631             0.024362                  9.870242               0.335727   \n",
      "17632             0.072951                  6.465457               0.422626   \n",
      "\n",
      "       Centroid Distance(accyz)  Polygon Area(accyz)  \\\n",
      "0                      0.399202             0.471914   \n",
      "1                      0.674483             0.833709   \n",
      "2                      0.451814             0.083674   \n",
      "3                      3.522641             3.416576   \n",
      "4                      0.625104             0.156925   \n",
      "...                         ...                  ...   \n",
      "17628                  0.407198             0.285554   \n",
      "17629                  0.314580             0.241416   \n",
      "17630                  0.340417             0.350555   \n",
      "17631                  0.319892             1.157944   \n",
      "17632                  0.227916             0.227560   \n",
      "\n",
      "       Polygon Perimeter(accyz)  Ferret Measure(acczx)  \\\n",
      "0                     12.862190               2.863775   \n",
      "1                     20.952302               0.509236   \n",
      "2                     22.086376               0.526429   \n",
      "3                     35.021401               2.634466   \n",
      "4                     16.248545               0.568957   \n",
      "...                         ...                    ...   \n",
      "17628                 21.223899               0.373479   \n",
      "17629                 18.248972               0.467442   \n",
      "17630                 17.036324               0.755179   \n",
      "17631                 20.086476               2.895304   \n",
      "17632                 13.446345               0.324786   \n",
      "\n",
      "       Centroid Distance(acczx)  Polygon Area(acczx)  Polygon Perimeter(acczx)  \n",
      "0                      0.188755             0.021297                  6.197423  \n",
      "1                      0.180096             0.143342                  3.590862  \n",
      "2                      0.135639             0.012133                  3.025889  \n",
      "3                      1.646785             0.124263                 17.490223  \n",
      "4                      0.125642             0.089153                  3.228899  \n",
      "...                         ...                  ...                       ...  \n",
      "17628                  0.084747             0.017589                  3.697555  \n",
      "17629                  0.105985             0.048751                  5.106712  \n",
      "17630                  0.083622             0.008091                  1.878394  \n",
      "17631                  0.236960             0.099311                  4.379561  \n",
      "17632                  0.060704             0.012136                  2.056794  \n",
      "\n",
      "[17633 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Accelero_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9780a28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Ferret Measure(accxy)  Centroid Distance(accxy)  \\\n",
      "0      100669               0.653896                  0.307439   \n",
      "1      100669               1.046059                  0.356021   \n",
      "2      100669               1.561073                  0.288214   \n",
      "3      100669               0.985135                  4.509599   \n",
      "4      100669               1.534549                  0.371832   \n",
      "...       ...                    ...                       ...   \n",
      "17628  186676               1.183922                  0.158304   \n",
      "17629  186676               0.973371                  0.154844   \n",
      "17630  186676               1.094025                  0.142493   \n",
      "17631  186676               0.869119                  0.146733   \n",
      "17632  186676               0.942703                  0.115567   \n",
      "\n",
      "       Polygon Area(accxy)  Polygon Perimeter(accxy)  Ferret Measure(accyz)  \\\n",
      "0                 0.126997                 10.049717               0.740989   \n",
      "1                 0.396814                 11.305019               0.297710   \n",
      "2                 0.019777                 10.251685               0.253358   \n",
      "3                 4.987873                 35.311697               1.414049   \n",
      "4                 0.361496                  8.355046               0.408537   \n",
      "...                    ...                       ...                    ...   \n",
      "17628             0.033820                  9.379900               0.197403   \n",
      "17629             0.189392                  9.418644               0.290865   \n",
      "17630             0.049188                  8.843841               0.356121   \n",
      "17631             0.024362                  9.870242               0.335727   \n",
      "17632             0.072951                  6.465457               0.422626   \n",
      "\n",
      "       Centroid Distance(accyz)  Polygon Area(accyz)  \\\n",
      "0                      0.399202             0.471914   \n",
      "1                      0.674483             0.833709   \n",
      "2                      0.451814             0.083674   \n",
      "3                      3.522641             3.416576   \n",
      "4                      0.625104             0.156925   \n",
      "...                         ...                  ...   \n",
      "17628                  0.407198             0.285554   \n",
      "17629                  0.314580             0.241416   \n",
      "17630                  0.340417             0.350555   \n",
      "17631                  0.319892             1.157944   \n",
      "17632                  0.227916             0.227560   \n",
      "\n",
      "       Polygon Perimeter(accyz)  Ferret Measure(acczx)  ...  \\\n",
      "0                     12.862190               2.863775  ...   \n",
      "1                     20.952302               0.509236  ...   \n",
      "2                     22.086376               0.526429  ...   \n",
      "3                     35.021401               2.634466  ...   \n",
      "4                     16.248545               0.568957  ...   \n",
      "...                         ...                    ...  ...   \n",
      "17628                 21.223899               0.373479  ...   \n",
      "17629                 18.248972               0.467442  ...   \n",
      "17630                 17.036324               0.755179  ...   \n",
      "17631                 20.086476               2.895304  ...   \n",
      "17632                 13.446345               0.324786  ...   \n",
      "\n",
      "       Polygon Area(gyroxy)  Polygon Perimeter(gyroxy)  \\\n",
      "0                  0.423369                   6.120407   \n",
      "1                  0.004262                   4.980247   \n",
      "2                  0.006709                   4.109890   \n",
      "3                  2.700508                  15.419713   \n",
      "4                  0.166164                   5.134611   \n",
      "...                     ...                        ...   \n",
      "17628              0.123106                   4.975900   \n",
      "17629              0.003211                   7.123988   \n",
      "17630              0.032050                   2.759303   \n",
      "17631              0.074344                   5.116394   \n",
      "17632              0.090549                   2.887727   \n",
      "\n",
      "       Ferret Measure(gyroyz)  Centroid Distance(gyroyz)  \\\n",
      "0                    0.566303                   0.179661   \n",
      "1                    1.242532                   0.133076   \n",
      "2                    1.998975                   0.106603   \n",
      "3                    0.420213                   1.632013   \n",
      "4                    3.081395                   0.230317   \n",
      "...                       ...                        ...   \n",
      "17628                2.667752                   0.103266   \n",
      "17629                2.685323                   0.119757   \n",
      "17630                2.854115                   0.138280   \n",
      "17631                0.781973                   0.330728   \n",
      "17632                5.150000                   0.095842   \n",
      "\n",
      "       Polygon Area(gyroyz)  Polygon Perimeter(gyroyz)  \\\n",
      "0                  1.491053                   8.126881   \n",
      "1                  0.003931                   3.977403   \n",
      "2                  0.035998                   3.321722   \n",
      "3                  2.770916                  18.024492   \n",
      "4                  0.134135                   4.248676   \n",
      "...                     ...                        ...   \n",
      "17628              0.041392                   3.372787   \n",
      "17629              0.042997                   4.658971   \n",
      "17630              0.039409                   2.326254   \n",
      "17631              0.154903                   5.451413   \n",
      "17632              0.010040                   1.922962   \n",
      "\n",
      "       Ferret Measure(gyrozx)  Centroid Distance(gyrozx)  \\\n",
      "0                    2.863775                   0.188755   \n",
      "1                    0.509236                   0.180096   \n",
      "2                    0.526429                   0.135639   \n",
      "3                    2.634466                   1.646785   \n",
      "4                    0.568957                   0.125642   \n",
      "...                       ...                        ...   \n",
      "17628                0.373479                   0.084747   \n",
      "17629                0.467442                   0.105985   \n",
      "17630                0.755179                   0.083622   \n",
      "17631                2.895304                   0.236960   \n",
      "17632                0.324786                   0.060704   \n",
      "\n",
      "       Polygon Area(gyrozx)  Polygon Perimeter(gyrozx)  \n",
      "0                  0.021297                   6.197423  \n",
      "1                  0.143342                   3.590862  \n",
      "2                  0.012133                   3.025889  \n",
      "3                  0.124263                  17.490223  \n",
      "4                  0.089153                   3.228899  \n",
      "...                     ...                        ...  \n",
      "17628              0.017589                   3.697555  \n",
      "17629              0.048751                   5.106712  \n",
      "17630              0.008091                   1.878394  \n",
      "17631              0.099311                   4.379561  \n",
      "17632              0.012136                   2.056794  \n",
      "\n",
      "[17633 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'gyroxy_features', 'gyroyz_features', 'gyrozx_features' with your actual dataframe variables\n",
    "Accelero_all_df = Accelero_all_df\n",
    "Gyro_all_df = Gyro_all_df\n",
    "\n",
    "\n",
    "# Assuming the ID column is named correctly and exists in your dataframes\n",
    "# Extract the 'ID' column from one dataframe and set it aside\n",
    "id_column = Accelero_all_df[['ID']]  # Replace 'ID' with the actual column name if it's different\n",
    "\n",
    "# Drop the 'ID' column from the other dataframes to avoid duplication\n",
    "Accelero_all_df.drop(columns=['ID'], inplace=True)\n",
    "Gyro_all_df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Concatenate the dataframes horizontally\n",
    "All_df = pd.concat([id_column, Accelero_all_df,Gyro_all_df], axis=1)\n",
    "\n",
    "print(All_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d16dadc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\chiri\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chiri\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\chiri\\anaconda3\\lib\\site-packages (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chiri\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e862bcd",
   "metadata": {},
   "source": [
    "# KNN ALGORITHM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1da11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Accuracy: 0.6355648243023326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'All_df' is your DataFrame\n",
    "X = All_df.drop('ID', axis=1)  # Features\n",
    "y = All_df['ID']  # Labels\n",
    "\n",
    "kf = KFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "knn_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize KNN, fit on training data, and make predictions\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)  # You can change the number of neighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and append to list\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    knn_accuracies.append(accuracy)\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = sum(knn_accuracies) / len(knn_accuracies)\n",
    "print(f'Average KNN Accuracy: {average_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3f7b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Accuracy: 0.6378356136861352\n",
      "Combined Confusion Matrix:\n",
      "[[3361  427  198  195  148]\n",
      " [ 769 2134  315  138  203]\n",
      " [ 279  222 2575  195  119]\n",
      " [ 553  356  517  956  181]\n",
      " [ 543  501  290  237 2221]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'All_df' is your DataFrame\n",
    "X = All_df.drop('ID', axis=1)  # Features\n",
    "y = All_df['ID']  # Labels\n",
    "\n",
    "kf = KFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "knn_accuracies = []\n",
    "conf_matrices = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize KNN, fit on training data, and make predictions\n",
    "    knn = KNeighborsClassifier(n_neighbors=15)  # You can change the number of neighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and append to list\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    knn_accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate and store the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = sum(knn_accuracies) / len(knn_accuracies)\n",
    "print(f'Average KNN Accuracy: {average_accuracy}')\n",
    "\n",
    "# Sum the confusion matrices from each fold to get a combined confusion matrix\n",
    "combined_conf_matrix = np.sum(conf_matrices, axis=0)\n",
    "print('Combined Confusion Matrix:')\n",
    "print(combined_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e440562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = All_df.drop('ID', axis=1)  \n",
    "y = All_df['ID'] \n",
    "\n",
    "X_trainf, X_testf, y_trainf, y_testf = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24e4cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7405307325924246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "rf_classifier.fit(X_trainf, y_trainf)\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_testf)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_testf, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dc1e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=10, min_samples_leaf=5, \n",
    "                                       max_features='auto', random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_trainf, y_trainf)\n",
    "y_pred_rf = rf_classifier.predict(X_testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0a3c1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7285098661828079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_testf, y_pred_rf)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "713e76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "my_cv = StratifiedShuffleSplit(n_splits=5, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "939dbe7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=None, test_size=0.3,\n",
       "            train_size=0.7),\n",
       "             estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['entropy'],\n",
       "                         'min_impurity_decrease': [0.01, 0.007],\n",
       "                         'min_samples_leaf': [6, 10, 20, 40],\n",
       "                         'min_weight_fraction_leaf': [0.01, 0.02, 0.05]},\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier()\n",
    "my_param_grid = {'min_samples_leaf': [6, 10, 20, 40],\n",
    "                 'min_weight_fraction_leaf': [0.01, 0.02, 0.05],\n",
    "                 'criterion': ['entropy'],\n",
    "                 'min_impurity_decrease': [1e-2, 7e-3]}\n",
    "dt_model_gs = GridSearchCV(estimator=dt_classifier, \n",
    "                           param_grid=my_param_grid, \n",
    "                           cv=my_cv, \n",
    "                           scoring='accuracy',\n",
    "                           verbose = 0,\n",
    "                           return_train_score = True)\n",
    "dt_model_gs.fit(X_trainf, y_trainf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4533a8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'min_impurity_decrease': 0.007,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_weight_fraction_leaf': 0.01}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt_model_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cce8b96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.25595045, 0.22456322, 0.18955092, 0.27454271, 0.27333484,\n",
       "        0.19850788, 0.25625315, 0.24709344, 0.21552129, 0.26382146,\n",
       "        0.23760071, 0.20825939, 0.29280477, 0.25047722, 0.19261599,\n",
       "        0.29855609, 0.25029392, 0.18643022, 0.28836784, 0.26046591,\n",
       "        0.18184223, 0.27387171, 0.2520649 , 0.1963284 ]),\n",
       " 'std_fit_time': array([0.01544454, 0.00875864, 0.01196422, 0.01114568, 0.02081077,\n",
       "        0.01655137, 0.00965515, 0.01852273, 0.04149808, 0.01321912,\n",
       "        0.00944086, 0.01123856, 0.00430513, 0.01471579, 0.01268495,\n",
       "        0.0211878 , 0.00572198, 0.00625854, 0.00559934, 0.01390289,\n",
       "        0.0123151 , 0.01472688, 0.01557827, 0.01374963]),\n",
       " 'mean_score_time': array([0.00504227, 0.00477128, 0.00231586, 0.00420728, 0.00496426,\n",
       "        0.00579777, 0.00325842, 0.00759182, 0.00234208, 0.00511289,\n",
       "        0.00341005, 0.00261312, 0.00682034, 0.00502667, 0.0044281 ,\n",
       "        0.0070785 , 0.00645475, 0.0038559 , 0.00468655, 0.00406818,\n",
       "        0.00938239, 0.00453353, 0.00196471, 0.00526795]),\n",
       " 'std_score_time': array([0.00814717, 0.00629409, 0.00287584, 0.00289061, 0.00124707,\n",
       "        0.00523019, 0.00410757, 0.00422485, 0.00282566, 0.00271242,\n",
       "        0.00312801, 0.00321663, 0.00583975, 0.00645973, 0.00596111,\n",
       "        0.00547061, 0.00220955, 0.00373659, 0.00383188, 0.00605977,\n",
       "        0.0076607 , 0.00589409, 0.00240684, 0.00592995]),\n",
       " 'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_impurity_decrease': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.007, 0.007, 0.007, 0.007, 0.007,\n",
       "                    0.007, 0.007, 0.007, 0.007, 0.007, 0.007, 0.007],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[6, 6, 6, 10, 10, 10, 20, 20, 20, 40, 40, 40, 6, 6, 6,\n",
       "                    10, 10, 10, 20, 20, 20, 40, 40, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_weight_fraction_leaf': masked_array(data=[0.01, 0.02, 0.05, 0.01, 0.02, 0.05, 0.01, 0.02, 0.05,\n",
       "                    0.01, 0.02, 0.05, 0.01, 0.02, 0.05, 0.01, 0.02, 0.05,\n",
       "                    0.01, 0.02, 0.05, 0.01, 0.02, 0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.01,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 6,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_weight_fraction_leaf': 0.05},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.01},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.02},\n",
       "  {'criterion': 'entropy',\n",
       "   'min_impurity_decrease': 0.007,\n",
       "   'min_samples_leaf': 40,\n",
       "   'min_weight_fraction_leaf': 0.05}],\n",
       " 'split0_test_score': array([0.53528226, 0.52217742, 0.47908266, 0.53528226, 0.52217742,\n",
       "        0.47908266, 0.53528226, 0.52217742, 0.47908266, 0.53528226,\n",
       "        0.52217742, 0.47908266, 0.54107863, 0.53049395, 0.47908266,\n",
       "        0.54107863, 0.53049395, 0.47908266, 0.54107863, 0.53049395,\n",
       "        0.47908266, 0.54107863, 0.53049395, 0.47908266]),\n",
       " 'split1_test_score': array([0.52016129, 0.51184476, 0.4672379 , 0.52016129, 0.51184476,\n",
       "        0.4672379 , 0.52016129, 0.51184476, 0.4672379 , 0.52016129,\n",
       "        0.51184476, 0.4672379 , 0.52444556, 0.51083669, 0.4672379 ,\n",
       "        0.52444556, 0.51083669, 0.4672379 , 0.52444556, 0.51083669,\n",
       "        0.4672379 , 0.52444556, 0.51083669, 0.4672379 ]),\n",
       " 'split2_test_score': array([0.53402218, 0.52797379, 0.49924395, 0.53402218, 0.52797379,\n",
       "        0.49924395, 0.53402218, 0.52797379, 0.49924395, 0.53402218,\n",
       "        0.52797379, 0.49924395, 0.53956653, 0.53024194, 0.49924395,\n",
       "        0.53956653, 0.53024194, 0.49924395, 0.53956653, 0.53024194,\n",
       "        0.49924395, 0.53956653, 0.53024194, 0.49924395]),\n",
       " 'split3_test_score': array([0.50957661, 0.50957661, 0.48739919, 0.50957661, 0.50957661,\n",
       "        0.48739919, 0.50957661, 0.50957661, 0.48739919, 0.50957661,\n",
       "        0.50957661, 0.48739919, 0.53099798, 0.52671371, 0.49495968,\n",
       "        0.53099798, 0.52671371, 0.49495968, 0.53099798, 0.52671371,\n",
       "        0.49495968, 0.53099798, 0.52671371, 0.49495968]),\n",
       " 'split4_test_score': array([0.56426411, 0.54435484, 0.53956653, 0.56426411, 0.54435484,\n",
       "        0.53956653, 0.56426411, 0.54435484, 0.53956653, 0.56426411,\n",
       "        0.54435484, 0.53956653, 0.56350806, 0.54964718, 0.53956653,\n",
       "        0.56350806, 0.54964718, 0.53956653, 0.56350806, 0.54964718,\n",
       "        0.53956653, 0.56350806, 0.54964718, 0.53956653]),\n",
       " 'mean_test_score': array([0.53266129, 0.52318548, 0.49450605, 0.53266129, 0.52318548,\n",
       "        0.49450605, 0.53266129, 0.52318548, 0.49450605, 0.53266129,\n",
       "        0.52318548, 0.49450605, 0.53991935, 0.52958669, 0.49601815,\n",
       "        0.53991935, 0.52958669, 0.49601815, 0.53991935, 0.52958669,\n",
       "        0.49601815, 0.53991935, 0.52958669, 0.49601815]),\n",
       " 'std_test_score': array([0.01842071, 0.01253714, 0.02483882, 0.01842071, 0.01253714,\n",
       "        0.02483882, 0.01842071, 0.01253714, 0.02483882, 0.01842071,\n",
       "        0.01253714, 0.02483882, 0.0132433 , 0.01235712, 0.02458903,\n",
       "        0.0132433 , 0.01235712, 0.02458903, 0.0132433 , 0.01235712,\n",
       "        0.02458903, 0.0132433 , 0.01235712, 0.02458903]),\n",
       " 'rank_test_score': array([ 5, 13, 21,  5, 13, 21,  5, 13, 21,  5, 13, 21,  1,  9, 17,  1,  9,\n",
       "        17,  1,  9, 17,  1,  9, 17]),\n",
       " 'split0_train_score': array([0.54764477, 0.52636128, 0.48120138, 0.54764477, 0.52636128,\n",
       "        0.48120138, 0.54764477, 0.52636128, 0.48120138, 0.54764477,\n",
       "        0.52636128, 0.48120138, 0.55553155, 0.53759723, 0.48120138,\n",
       "        0.55553155, 0.53759723, 0.48120138, 0.55553155, 0.53759723,\n",
       "        0.48120138, 0.55553155, 0.53759723, 0.48120138]),\n",
       " 'split1_train_score': array([0.54256698, 0.53251945, 0.49297753, 0.54256698, 0.53251945,\n",
       "        0.49297753, 0.54256698, 0.53251945, 0.49297753, 0.54256698,\n",
       "        0.53251945, 0.49297753, 0.55077787, 0.53500432, 0.49297753,\n",
       "        0.55077787, 0.53500432, 0.49297753, 0.55077787, 0.53500432,\n",
       "        0.49297753, 0.55077787, 0.53500432, 0.49297753]),\n",
       " 'split2_train_score': array([0.53284356, 0.5261452 , 0.48941227, 0.53284356, 0.5261452 ,\n",
       "        0.48941227, 0.53284356, 0.5261452 , 0.48941227, 0.53284356,\n",
       "        0.5261452 , 0.48941227, 0.5514261 , 0.53910977, 0.48941227,\n",
       "        0.5514261 , 0.53910977, 0.48941227, 0.5514261 , 0.53910977,\n",
       "        0.48941227, 0.5514261 , 0.53910977, 0.48941227]),\n",
       " 'split3_train_score': array([0.53316768, 0.53025065, 0.49643475, 0.53316768, 0.53025065,\n",
       "        0.49643475, 0.53316768, 0.53025065, 0.49643475, 0.53316768,\n",
       "        0.53025065, 0.49643475, 0.55726016, 0.54267502, 0.50734659,\n",
       "        0.55726016, 0.54267502, 0.50734659, 0.55726016, 0.54267502,\n",
       "        0.50734659, 0.55726016, 0.54267502, 0.50734659]),\n",
       " 'split4_train_score': array([0.55790838, 0.53651685, 0.53197926, 0.55790838, 0.53651685,\n",
       "        0.53197926, 0.55790838, 0.53651685, 0.53197926, 0.55790838,\n",
       "        0.53651685, 0.53197926, 0.56039326, 0.54742869, 0.53197926,\n",
       "        0.56039326, 0.54742869, 0.53197926, 0.56039326, 0.54742869,\n",
       "        0.53197926, 0.56039326, 0.54742869, 0.53197926]),\n",
       " 'mean_train_score': array([0.54282627, 0.53035869, 0.49840104, 0.54282627, 0.53035869,\n",
       "        0.49840104, 0.54282627, 0.53035869, 0.49840104, 0.54282627,\n",
       "        0.53035869, 0.49840104, 0.55507779, 0.54036301, 0.50058341,\n",
       "        0.55507779, 0.54036301, 0.50058341, 0.55507779, 0.54036301,\n",
       "        0.50058341, 0.55507779, 0.54036301, 0.50058341]),\n",
       " 'std_train_score': array([0.00942017, 0.00390733, 0.01753513, 0.00942017, 0.00390733,\n",
       "        0.01753513, 0.00942017, 0.00390733, 0.01753513, 0.00942017,\n",
       "        0.00390733, 0.01753513, 0.00360685, 0.00431752, 0.01783113,\n",
       "        0.00360685, 0.00431752, 0.01783113, 0.00360685, 0.00431752,\n",
       "        0.01783113, 0.00360685, 0.00431752, 0.01783113])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best_classifier = dt_model_gs.best_estimator_\n",
    "dt_model_gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92a1cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5696003150226423,\n",
       " 0.550305178184682,\n",
       " 0.5471549517621579,\n",
       " 0.5662531994487103,\n",
       " 0.5442016144910415]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best_classifier.get_params()\n",
    "dt_best_classifier.get_depth()\n",
    "dt_best_classifier.get_n_leaves()\n",
    "scores = cross_val_score(dt_best_classifier, X_train, y_train, cv=my_cv, scoring='accuracy')\n",
    "list(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1357630e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5564744801512287"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best_classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d70262b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cd92596",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression(verbose = 0)\n",
    "my_param_grid = {'C': [10, 50, 100, 200]}\n",
    "lr_model_gs = GridSearchCV(estimator=lr_classifier, \n",
    "                           param_grid=my_param_grid, \n",
    "                           cv=my_cv, \n",
    "                           scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b54ce7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=None, test_size=0.3,\n",
       "            train_size=0.7),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': [10, 50, 100, 200]}, scoring='accuracy')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0da37a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_classifier = lr_model_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37d32342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 200,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best_classifier.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f18ad3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5812167749556999,\n",
       " 0.5790509942902146,\n",
       " 0.5753101004134672,\n",
       " 0.5818074424099232,\n",
       " 0.5833825556211852]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lr_best_classifier, X_train, y_train, cv=my_cv, scoring='accuracy')\n",
    "list(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "629caa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=lr_best_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca298685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5828804347826086"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "720f546f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Accuracy: 0.6093028908060778\n",
      "Combined Confusion Matrix:\n",
      "[[3293  471  164  225  176]\n",
      " [ 865 2039  267  167  221]\n",
      " [ 338  357 2372  201  122]\n",
      " [ 645  416  456  869  177]\n",
      " [ 629  543  258  191 2171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'label_column' is the name of your label column\n",
    "X = All_df.drop('ID', axis=1)  # Features\n",
    "y = All_df['ID']  # Labels\n",
    "\n",
    "# Define KFold cross-validator\n",
    "kf = KFold(n_splits=50, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "conf_matrices = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split data into training and test sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create and train the KNN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)  # You can change the number of neighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    predictions = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Compute and store the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average KNN Accuracy: {average_accuracy}')\n",
    "\n",
    "# Optional: Combine confusion matrices from all folds\n",
    "combined_conf_matrix = np.sum(conf_matrices, axis=0)\n",
    "print('Combined Confusion Matrix:')\n",
    "print(combined_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8923776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
